# 02-03. 확률, 통계 및 트래픽 이론

---

## 2.2 기본적인 확률 및 통계 이론

---

### 2.2.5 몇 가지 중요한 분포함수 (이산 랜덤 변수)

---

- 일반적인 사건의 발생이 어떠한 서로 다른 분포들로 표현될 수 있는지 알아본다.
- 확률 함수로부터 나온 확률들의 패턴

#### 이산 랜덤 변수

- 질량 함수 → 이산형 확률분포(Discrete probability distribution)

##### 분포 종류

- 베르누이 분포, Bernoulli distribution
- 바이노미얼 분포, Binomial distribution
- 푸아송 분포, Poisson distribution
- 지오메트릭 분포, Geometric distribution
- Negative Binomial distribution
- Hypergeometric distribution



#### Bernoulli Distribution (베르누이 분포)

- 확률 변수 X가 두 가지 값만 가지는 단순한 확률
  - 1 = "success" or 0 = "failure"

$$
\mbox{Define } p= P[success] = P[X=1]\\
p=\begin{cases}
0, & \rightarrow 1-p\\
1, & \rightarrow p
\end{cases}
$$

- 0과 1을 확률로 바꾸는 확률 함수가 필요하며, 아래 확률 함수를 따르는 확률 분포를 베르누이 분포라 한다.

$$
f_X(x;p) = p^x\cdot (1-p)^{1-x}, \quad x=\mbox{0 or 1}
$$

- 즉, 베르누이 분포는 위의 베르누이 확률 함수로부터 생성되는 확률들의 패턴을 그린 것



##### 베르누이 확률 분포의 기대값과 분산

- 기대값 E[X] = p

$$
\mbox{기대값의 정의: }\quad E[X]=\sum x\cdot p^x \cdot (1-p)^{1-x}\\
\mbox{베르누이 확률 분포의 기대값: }\quad E[X] = \sum_{x=\mbox{0 or 1}}x\cdot p^x \cdot (1-p)^{1-x} = 0 + p = p
$$

- 분산 V[X] = p(1-p)

$$
V[X] = E[X^2] - \{E[X]\}^2\\
E[X^2] = \sum_{x=\mbox{0 or 1}}x^2\cdot p^x \cdot (1-p)^{1-x} = 0+p = p\\
\therefore p-p^2 = p(1-p)
$$

- 예) 1

  >동전을 던져서 앞 또는 뒤가 나올 경우와 같은 상황에서 사용
  >
  >동전을 던져서 앞은 1, 뒤는 0이라 설정, 그 상황에서 나오는 확률은 1/2로 정의



#### Binomial Distribution (이항 분포)

- 베르누이 분포로 부터 나온 분포
  - 베르누이를 한 번만 던지면 베르누이 시행(Bernoulli trial)이라 부름
  - 그런 베르누이 시행을 독립적으로 n번 시도한 것
    - 첫 번째 시행이 다음 시행에 영향을 주는 종속적인 관계가 아닌 것
  
- 이 때의 확률 변수 X를 정의한다.
  - X는 n번 시행해서 나오는 총 성공의 횟수
  
  - 여기서 X는 X={0, 1, 2, ... , n}으로 구성되며, 성공의 최대 횟수는 n번 모두 성공했을 때 즉, n이 된다.
  
  - 해당 실수 값들을 확률로 변경 해야 하며, 그 확률 함수는 아래와 같음
    $$
    p(x)= \begin{pmatrix} n \\ x\end{pmatrix}p^x \cdot (1-p)^{n-x} \qquad \mbox{for }x=0, 1, \dots, n \\
    \begin{pmatrix} n \\ x\end{pmatrix}\mbox{: n 번 중에 성공한 x의 횟수 즉, n번 중에서 x개를 선택한 것}\\
    p^x\mbox{: 성공한 횟수}\\
    (1-p)^{n-x}\mbox{: 실패한 횟수}
    $$
  
    - Parameter n and p: 위의 확률 함수로부터 나온 확률 분포의 모양을 결정하는데 영향을 주는 변수(or 모수)들
    - Parameter에 의한 그래프 모양의 예)
  
    <img src="./assets_02/images/bimonial.png" style="zoom:70%;" alt="Parameter에 의한 그래프 모양의 예"/>
  
  -  위의 x들을 확률 함수에 넣으면 0~1 사이의 값으로 생성
  -  이 함수의 분포는 이산형 확률 함수가 됨
  
- 이항 확률 함수의 모든 합이 1이 되는가?
  $$
  \sum^n_{x=0}p(x)= \sum^n_{x=0}{\begin{pmatrix}n\\x\end{pmatrix}}p^x(1-p)^{n-x}= 1\\
  \mbox{Why?}\\
  \mbox{Binomial Theorem에 의한 결과: }(x+y)^n = \sum^n_{i=0} {\begin{pmatrix}n\\i\end{pmatrix}}x^i \cdot y^{n-i}\\
  \mbox{위의 식에서는 }x\mbox{가 }p\mbox{이고, }y\mbox{가 }1-p\mbox{로 표현 된 것}\\
  \therefore (p+1-p)^n = 1^n = 1
  $$

- 확률 변수가 주어지고 parameter가 주어질 때의 기대값과 분산

  - 기대값 E[X]
    $$
    {\begin{pmatrix}n\\x\end{pmatrix}}\mbox{는 다음과 같이 쓸 수 있음 }=\frac{i \cdot n!}{(n-i)! \cdot i!}\\
    E[X] = \sum^n_{i=0}\frac{i \cdot n!}{(n-i)! \cdot i!}\cdot p^i(1-p)^{n-i}\\
    =np \sum_{i=1}^n \frac{i \cdot (n-1)!}{(n-i)! \cdot i!}\cdot p^{i-1}(1-p)^{n-i}\\
    =np \sum_{i=1}^n \frac{(n-1)!}{(n-i)! \cdot (i-1)!}\cdot p^{i-1}(1-p)^{n-i}\mbox{, let }{\begin{cases}i-1=k,\\i=k+1\end{cases}}\\
    = np\sum_{k=0}^n \frac{(n-1)!}{(n-k-1)!\cdot k!}p^k(1-p)^{n-1-k}\mbox{, & Binomial Theorem에의해 아래와 같이 변경 됨}\\
    = np\{p+(1-p)^{n-1}\}^{n-1}\\
    \therefore E[X] = np
    $$

  - 분산 V[X]
    $$
    E[X^2]=np[(n-1)\cdot p+1]\\
    V[X] = E[X^2] - \{E[X]\}^2\\
    \therefore V[X] = np(1-p)
    $$

- 예) 1

  불량의 갯수 파악
  
  >0 = 정상, 1 = 불량
  >
  >n = 10개의 부품, p=P[불량품]=0.1
  >
  >10개의 부품 중 2개가 불량일 확률은?
  >
  >
  >
  >확률변수 정의
  >$$
  >X\mbox{: 불량품의 갯수}\\
  >X=\{0, 1, 2,...,10\}\\
  >P[X=2] = {\begin{pmatrix}10\\2\end{pmatrix}}(0.1)^2(0.9)^{10-2}=0.1937
  >$$
  >기대값 E[X]과 분산 V[X]
  >$$
  >E[X] = (10)\cdot (0.1) = 1\mbox{, 평균적으로 1개의 불량이 나옴}\\
  >V[X] = (10)\cdot (0.1) \cdot (0.9) = 0.9
  >$$

- 예) 2

  >불량률이 6%인 공정에서 매주 랜덤하게 50개를 뽑음
  >
  >1. 확률 변수 X는?
  >
  >$$
  >X = \{0, 1, 2, 3, ... , 50\}
  >$$
  >
  >2. 그 중에서 불량이 3개 일 때의 확률은?
  >
  >$$
  >X\mbox{~ Bino}(50, 0.06)\\
  >P(X=3)={\begin{pmatrix}50\\3\end{pmatrix}}\cdot 0.06^3 \cdot (1-0.06)^{50-3}
  >$$
  >
  >3. P(X>3)일 확률은?
  >
  >$$
  >1-P(X\leq3)\mbox{을 이용}\\
  >1-\{P(X=3)+P(X=2)+P(X=1)\}\\
  >= 1-\sum^3_{i=0}{\begin{pmatrix}n\\i\end{pmatrix}}0.06^i(1-0.06)^{50-i}
  >$$

- Binomial Distribution Proposition

  - 이산 확률 변수 X와 parameter n과 p가 있다.

  - 여기서 p는 0 < p < 1을 만족한다.

  - X가 가질 수 있는 값이 k라 할 때, k는 0 ~ n까지 가진다.

  - P{X=k}의 값이 증가했다 감소를 하게 되는 분포 그래프가 생긴다.

  - 이 때, 가장 꼭대기(가장 큰)값이 (n+1)p로 정의 된다.

  - 증명
    $$
    P\{X=k\}/P\{X=k-1\}\mbox{에서 비율을 계산 한 뒤에 어떤 k가 1보다 작거나 큰 값을 찾아 냄}\\
    \frac{P\{X=k\}}{P\{X=k-1\}}=\frac{\frac{n!}{(n-k)!k!}p^k(1-p)^{n-k}}{\frac{n!}{(n-k+1)!(k-1)!}p^{k-1}(1-k)^{n-k+1}}\\
    =\frac{(n-k+1)p}{k(1-p)} > 1\\
    \because P\{X=k\}\geq P\{X=k-1\}\\
    \therefore (n-k+1)p \geq k(1-p)
    $$



#### Poisson distribution (푸아송 분포)

- 확률 변수 X={0, 1, 2, ...}와 같이 이산형 실수 값을 가지게 되며 아래의 확률 함수로부터 생성된 확률들의 패턴을 나타냄
- Parameter로 λ를 사용하게 되며 이 값은 0보다 큼
  - 단위 시간(or 공간) 안에 특정 사건이 몇 번 발생할 것 인지를 표현한 확률 분포

$$
P\{X=i\}=\frac{e^{-\lambda}\lambda^i}{i!}, \quad \mbox{for }\quad i=\{0, 1, 2,\dots\}, \quad \lambda>0
$$

- 푸아송 분포의 성질

$$
\mbox{모든 확률의 합}\\
\sum^\infty_{i=0}P(X=i)\quad = e^{-\lambda}\sum^\infty_{i=0}\frac{\lambda^i}{i!}=e^{-\lambda}\cdot e^\lambda = 1\\
\because \sum^\infty_{i=0}\frac{\lambda^i}{i!} \mbox{의 값은 테일러 급수에 의해서 }e^\lambda \mbox{로 만들어 짐}
$$

- Parameter λ에 따른 푸아송 분포의 그래프

<img src="./assets_02/images/Poisson_pmf.png" alt="푸아송 분포 그래프" style="zoom: 45%;" />

- 푸아송 분포와 Binomial 분포의 관계

  - p(i; n, p) ≈ p(i; λ)
  - 좌측: Binomial 분포, 우측: 푸아송 분포
  - n이 무한대로 커지고, p가 작아질 때, λ = np 와 같아 지게 됨

  $$
  P\{X=i\} = \frac{n!}{(n-i)!\cdot i!}p^i\cdot (1-p)^{n-i} \thickapprox e^{-\lambda} \frac{\lambda^i}{i!}
  $$

  - 증명
    $$
    p = \frac{\lambda}{n} \mbox{를 이용}\\
    = \frac{n!}{(n-i)! \cdot i!}\Big(\frac{\lambda}{n}\Big)^i \cdot (1- \frac{\lambda}{n})^{n-i}\\
    = \frac{n(n-1)\cdots (n-i+1)}{n^i}\cdot\frac{\lambda^i}{i!}\cdot \frac{(1-\frac{\lambda}{n})^n}{(1-\frac{\lambda}{n})^i}\\
    $$

    - 잠시 정리
      $$
      \mbox{앞의 }\frac{n(n-1)\cdots (n-i+1)}{n^i}\cdot\frac{\lambda^i}{i!}\mbox{를 1번}\mbox{ 뒤의 분모 }(1-\frac{\lambda}{n})^i \mbox{를 2번, 분자 } (1-\frac{\lambda}{n})^n\mbox{를 3번으로 지칭}\\
      \\
      \mbox{1. }\lim_{n\to\infty} = 1\\
      \mbox{2. }\lim_{n\to\infty}(1-\frac{\lambda}{n})^i = 1\\
      \mbox{3. }\lim_{n\to\infty}(1-\frac{\lambda}{n})^n = \lim_{n\to\infty}\Big\{(1-\frac{\lambda}{n})^{\frac{n}{\lambda}}\Big\}^\lambda = (e^{-1})^\lambda = e^{-\lambda}\\
      $$

  - 증명 이어서
    $$
    = 1 \cdot \frac{\lambda^i}{i!}\frac{e^{-\lambda}}{1}=\frac{e^{-\lambda}\cdot \lambda^i}{i!} = \mbox{푸아송 분포}
    $$
  
- 예제
  - 어떤 집단에서 사람 수 n중에 100세 이상인 사람의 수
  - 책의 모든 페이지에서 오타의 갯수
  - 매일 전화를 걸 때, 잘못 걸을 횟수
  
- 푸아송 확률 변수의 기대값과 분산
  - 결과적으로 기대값과 분산은 parameter λ와 같음
  - 기대값
  
  $$
  E[X] = \sum^\infty_{i=0}i\cdot \frac{e^{-\lambda}\lambda^i}{i!}\\
  = \lambda \sum^\infty_{i=1}\frac{e^{-\lambda}\lambda^{i-1}}{(i-1)!}\quad\mbox{, Let} k=i-1\\
  = \lambda \sum^\infty_{k=0}\frac{e^{-\lambda}\lambda^k}{k!}\\
  = \lambda e^{-\lambda}\sum^\infty_{k=0}\frac{\lambda^k}{k!}\\
  = \lambda e^{-\lambda} e^\lambda = \lambda
  $$
  
  - 분산
  
  $$
  E[X^2]=\lambda(\lambda+1)\\
  V[X]=E[X^2]-\{E[X]\}^2\\
  V[X]=\lambda^2+\lambda-\lambda^2 = \lambda
  $$



#### Geometric Distribution (기하 분포)

- 베르누이 시행에서부터 시작

- 확률 변수 X: 첫 번째 성공이 일어나기 까지 필요한 시행 횟수

  - p = P[success]를 기반으로 아래 기하 확률 함수를 따름
    $$
    P\{X=n\}=(1-p)^{n-1}p \quad \mbox{, for }n=1, 2, \dots
    $$

  - 예)

    >5번 시행에서 첫 번째 성공일 때를 가정
    >
    >1. Fail → (1-p)
    >2. Fail → (1-p)
    >3. Fail → (1-p)
    >4. Fail → (1-p)
    >5. Success → p

- 모든 확률의 합

  - 첫 번째는 먼저 시행을 해야 함 즉, 시행 횟수는 1 부터 시작 됨

  $$
  \sum^\infty_{n=1}P\{X=n\} = p\cdot \sum^\infty_{n=1}(1-p)^{n-1}=\frac{p}{1-(1-p)} = 1
  $$

- X가 기하 확률 함수를 따르게 되며 기하 확률 분포는 parameter p를 가짐

- 기대값 E[X] = 1/p
  $$
  P(X=i)=\sum^\infty_{i=1} i\cdot(1-p)^{i-1}\cdot p\\
  =p \sum^\infty_{i=1}i\cdot(1-p)^{i-1} \quad\mbox{, Let } 1-p = k \mbox{ &}p=1-k\\
  =p \sum^\infty_{i=1}i\cdot k^{i-1}\\
  =p \sum^\infty_{i=1}\frac{d}{dk}k^i\\
  =p \cdot\frac{d}{dk}\cdot\sum^\infty_{i=1}k^i\\
  =p \cdot\frac{d}{dk}\cdot\Big(\frac{k}{1-k}\Big)\\
  =p \cdot\frac{1-k+k}{(1-k)^2}\\
  =p \cdot\frac{1}{p^2} = \frac{1}{p}
  $$

  >팁) i 곱하기 k의 i-1제곱은 k에 대하여 미분한 것
  >$$
  >i \cdot k^{i-1} = \frac{d}{dk}k^i
  >$$

- 분산 V[X] = (1-p)p^2
  $$
  E[X^2] = \frac{2-p}{p^2}\\
  V[X] = \frac{2-p}{p^2} - \frac{1}{p^2} = \frac{1-p}{p^2}
  $$

- 예)

  >항아리에 N개의 흰색 공과 M개의 검은색 공이 있다.
  >
  >공을 랜덤하게 선택하는데, 검은색 공이 뽑힐 때 까지 시행한다.
  >
  >- 다음 공이 뽑힐 때는 뽑았던 공은 다시 넣는다. (복원 추출 or 독립 시행)
  >
  >
  >
  >(a) 검은색 공이 첫 번째 뽑힐 때 까지 필요한 횟수가 n번일 확률은?
  >
  >- 확률 변수 X: 검은색 공이 첫 번째 뽑힐 때 까지 필요한 시행 횟수(공 뽑기)
  > $$
  >  P(W) = \frac{N}{N+M} \quad\mbox{, } P(B) = \frac{M}{N+M}
  > $$
  >
  >- n-1번째 까지는 흰색 공이 나와야 함
  > $$
  >  P\{X=n\}=\Big(\frac{N}{N+M}\Big)^{n-1}\cdot\frac{M}{N+M}\\
  >  = \frac{M\cdot N^{n-1}}{(N+M)^n}
  > $$
  >
  >
  >
  >(b) 검은색 공이 뽑힐 때 까지 적어도 k번이 필요할 확률은?
  >
  >- 확률 변수 X가 k를 포함한 횟수 이상을 시행
  > 
  > $$
  >  P\{X \geq k\} = \frac{M}{N+M} \cdot \sum^\infty_{n=k}\Big(\frac{N}{N+M}\Big)^{n-1}\\
  >  = \Big(\frac{M}{N+M})\cdot\Big(\frac{N}{N+M}\Big)^{k-1} \Big/\Big[1-\frac{N}{N+M}\Big]\\
  >  = \Big(\frac{N}{N+M}\Big)^{k-1}
  > $$

